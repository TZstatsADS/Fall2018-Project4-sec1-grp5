install_github("trinker/pacman")
}
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #97 files in total
### only process one of the files in the folder as an example, in your project, you need to use all the files
current_file_name <- sub(".txt","",file_name_vec[3])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
# if (!require("devtools")) install.packages("devtools")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(rlist)
# if (!require("devtools")) install.packages("devtools")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(rlist)
install.packages("rlist")
# if (!require("devtools")) install.packages("devtools")
# if (!require("rlist")) install.packages("rlist")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(rlist)
# setwd("E:/study/Columbia University/2018FALL/ads5243/project4/Fall2018-Project4-sec1--sec1-proj4-grp5")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
clean_txt<-function(t){
current_txt <- readLines(t,warn=FALSE,encoding = "UTF-8")
current_txt =gsub("[^A-Za-z ]","",current_txt)
current_txt =trimws(current_txt)
return(tolower(current_txt))
}
ground_truth<-list()
orc_txt<-list()
for(i in 1:length(file_name_vec)){
ground_truth[[i]] <- clean_txt(paste("../data/ground_truth/",
file_name_vec[i],sep=""))
orc_txt[[i]] <- clean_txt(paste("../data/tesseract/",
file_name_vec[i],sep=""))
}
not_equal_txt<-matrix(ncol=4)
for(i in 1:length(file_name_vec)){
if(length(ground_truth[[i]])!=length(orc_txt[[i]])){
not_equal_txt<-rbind(not_equal_txt,c(length(ground_truth[[i]]),
length(orc_txt[[i]]),
file_name_vec[i],i))
}
}
ground_truth[[3]]<-ground_truth[[3]][1:291]
#check the txt manually and make correction
ground_truth
ground_truth[[3]]<-ground_truth[[3]][1:291]
orc_txt[[3]]<-orc_txt[[3]][1:291]
#delete No.10 txt
#delete No.22 txt
ground_truth[[23]]<-ground_truth[[23]][1:222]
orc_txt[[23]]<-orc_txt[[23]][1:222]
ground_truth[[34]]<-ground_truth[[34]][1:466]
orc_txt[[34]]<-orc_txt[[34]][1:466]
ground_truth[[41]]<-ground_truth[[41]][1:740]
orc_txt[[41]]<-orc_txt[[41]][1:740]
ground_truth[[61]]<-ground_truth[[61]][-c(498,499)]
ground_truth[[63]]<-ground_truth[[63]][1:674]
orc_txt[[63]]<-orc_txt[[63]][1:674]
ground_truth[[68]]<-ground_truth[[68]][1:891]
orc_txt[[68]]<-orc_txt[[68]][1:891]
#delete No.70
ground_truth[[72]]<-ground_truth[[72]][-499]
#delete No.80
ground_truth[[100]]<-ground_truth[[100]][1:803]
#the txt pairs we can use
txt_file_num<-c(1:9,11:21,23:69,71:79,81:100)# to
source("./lib/ErrorDetection/2gram_error_detector.R")
source("./lib/ErrorDetection/2gram_error_detector.R")
source("./lib/ErrorDetection/orc_txt_error_detector.R")
truth_corpus = list()
truth_dict = list()
for(i in 1:length(ground_truth)){
truth_corpus[[i]] <- VCorpus(VectorSource(ground_truth[[i]]))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
truth_dict[[i]] <- tidy(truth_corpus[[i]]) %>%
select(text) %>%
unnest_tokens(dictionary, text)
}
orc_corpus = list()
orc_dict = list()
for(i in 1:length(orc_txt)){
orc_corpus[[i]] <- VCorpus(VectorSource(orc_txt[[i]]))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
orc_dict[[i]] <- tidy(orc_corpus[[i]]) %>%
select(text) %>%
unnest_tokens(dictionary, text)
}
for(i in 1:length(orc_dict)){
orc_dict[[i]] = orc_dict[[i]]$dictionary[nchar(orc_dict[[i]]$dictionary)>1]
}
for(j in 1:length(truth_dict)){
truth_dict[[j]] = truth_dict[[j]]$dictionary[nchar(truth_dict[[j]]$dictionary)>1]
}
error = neighbor_words(orc_dict[[5]],truth_dict[[5]]) # test for 1 document
ground_truth_vec <- str_split(paste(tesseract_vec, collapse = " ")," ")[[1]]
clean_tesseract_txt <- paste(current_tesseract_txt, collapse = " ")
#input: t is a txt file path; output is a cleaned txt
clean_txt<-function(t){
current_txt <- readLines(t,warn=FALSE,encoding = "UTF-8")
current_txt =gsub("[^A-Za-z ]","",current_txt)
current_txt =trimws(current_txt)
return(tolower(current_txt))
}
#get all the cleaned ground truth txt and cleaned orc txt
ground_truth<-list()
orc_txt<-list()
for(i in 1:length(file_name_vec)){
ground_truth[[i]] <- clean_txt(paste("../data/ground_truth/",
file_name_vec[i],sep=""))
orc_txt[[i]] <- clean_txt(paste("../data/tesseract/",
file_name_vec[i],sep=""))
}
#check the number of lines
not_equal_txt<-matrix(ncol=4)
for(i in 1:length(file_name_vec)){
if(length(ground_truth[[i]])!=length(orc_txt[[i]])){
not_equal_txt<-rbind(not_equal_txt,c(length(ground_truth[[i]]),
length(orc_txt[[i]]),
file_name_vec[i],i))
}
}
#check the txt manually and make correction
ground_truth[[3]]<-ground_truth[[3]][1:291]
orc_txt[[3]]<-orc_txt[[3]][1:291]
#delete No.10 txt
#delete No.22 txt
ground_truth[[23]]<-ground_truth[[23]][1:222]
orc_txt[[23]]<-orc_txt[[23]][1:222]
ground_truth[[34]]<-ground_truth[[34]][1:466]
orc_txt[[34]]<-orc_txt[[34]][1:466]
ground_truth[[41]]<-ground_truth[[41]][1:740]
orc_txt[[41]]<-orc_txt[[41]][1:740]
ground_truth[[61]]<-ground_truth[[61]][-c(498,499)]
ground_truth[[63]]<-ground_truth[[63]][1:674]
orc_txt[[63]]<-orc_txt[[63]][1:674]
ground_truth[[68]]<-ground_truth[[68]][1:891]
orc_txt[[68]]<-orc_txt[[68]][1:891]
#delete No.70
ground_truth[[72]]<-ground_truth[[72]][-499]
#delete No.80
ground_truth[[100]]<-ground_truth[[100]][1:803]
#the txt pairs we can use
txt_file_num<-c(1:9,11:21,23:69,71:79,81:100)# total 96 txt pairs
#remove the lines with different length in pairs
for(i in txt_file_num){
gt<-str_count(ground_truth[[i]],'\\w+')
ot<-str_count(orc_txt[[i]],'\\w+')
jud<-gt==ot
ground_truth[[i]]<-ground_truth[[i]][jud]
orc_txt[[i]]<-orc_txt[[i]][jud]
}
#the txt we can use now are ground_truth[[txt_file_num]] and orc_txt[[txt_file_num]]
#for text error detection and correction
##### detection part zx2229
source("./lib/ErrorDetection/2gram_error_detector.R")
# if (!require("devtools")) install.packages("devtools")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
#setwd("E:/study/Columbia University/2018FALL/ads5243/project4/Fall2018-Project4-sec1--sec1-proj4-grp5")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
for(i in c(1:length(file_name_vec))){
current_file_name <- sub(".txt","",file_name_vec[i])
## png folder is not provided on github (the code is only on demonstration purpose)
current_tesseract_txt <- tesseract::ocr(paste("../data/png/",current_file_name,".png",sep=""))
### clean the tessetact text (separate line by "\n", delete null string, transter to lower case)
clean_tesseract_txt <- strsplit(current_tesseract_txt,"\n")[[1]]
clean_tesseract_txt <- clean_tesseract_txt[clean_tesseract_txt!=""]
### save tesseract text file
writeLines(clean_tesseract_txt, paste("../data/tesseract/",current_file_name,".txt",sep=""))
}
### only process one of the files in the folder as an example, in your project, you need to use all the files
current_file_name <- sub(".txt","",file_name_vec[5])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
#clean_ground_truth_txt = paste(current_ground_truth_txt, collapse = " ") # zx2229
#ground_truth_vec <- str_split(clean_ground_truth_txt," ")[[1]] # zx2229
current_ground_truth_txt = gsub("..."," ",current_ground_truth_txt,fixed = TRUE)
current_ground_truth_txt = gsub("\"","", current_ground_truth_txt,fixed=TRUE)
corpus <- VCorpus(VectorSource(current_ground_truth_txt))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
## read the tesseract text
current_tesseract_txt <- readLines(paste("../data/tesseract/",current_file_name,".txt",sep=""), warn=FALSE)
clean_tesseract_txt <- paste(current_tesseract_txt, collapse = " ")
## detect tesseract word error
tesseract_vec <- str_split(clean_tesseract_txt," ")[[1]] #1124 tokens
tesseract_vec = gsub("..."," ",tesseract_vec,fixed = TRUE)
tesseract_vec = gsub("\"","", tesseract_vec,fixed=TRUE)
corpus <- VCorpus(VectorSource(tesseract_vec))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict_tesseract <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
tesseract_if_clean <- unlist(lapply(tesseract_vec,ifCleanToken)) # source code of ifCleanToken in in lib folder
# Save the ground truth dictionary
dictionary <- list()
for(i in 1:length(file_name_vec)){
current_file_name <- sub(".txt","",file_name_vec[i])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
#clean_ground_truth_txt = paste(current_ground_truth_txt, collapse = " ") # zx2229
#ground_truth_vec <- str_split(clean_ground_truth_txt," ")[[1]] # zx2229
current_ground_truth_txt = gsub("..."," ",current_ground_truth_txt,fixed = TRUE)
current_ground_truth_txt = gsub("\"","", current_ground_truth_txt,fixed=TRUE)
corpus <- VCorpus(VectorSource(current_ground_truth_txt))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dictionary[[i]] <- dict
path <- "/Users/janechen/Documents/GitHub/Fall2018-Project4-sec1--sec1-proj4-grp5/data/ground_truth/"
csv_name <- paste0(paste0(path, current_file_name),".csv")
write.csv(dictionary[[i]], file = csv_name)
}
current_file_name
current_group <- sub("_","",current_file_name)
current_group
current_group <- substr(current_file_name,1,6)
current_group
dict
group <- c(group, current_group)
group <- c()
group <- c(group, current_group)
group <- c(group, current_group)
list(current_group, dict)
group <- c()
dictionary <- list()
for(i in 1:length(file_name_vec)){
current_file_name <- sub(".txt","",file_name_vec[i])
current_group <- substr(current_file_name,1,6)
group <- c(group, current_group)
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
#clean_ground_truth_txt = paste(current_ground_truth_txt, collapse = " ") # zx2229
#ground_truth_vec <- str_split(clean_ground_truth_txt," ")[[1]] # zx2229
current_ground_truth_txt = gsub("..."," ",current_ground_truth_txt,fixed = TRUE)
current_ground_truth_txt = gsub("\"","", current_ground_truth_txt,fixed=TRUE)
corpus <- VCorpus(VectorSource(current_ground_truth_txt))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dictionary[[i]] <- dict
}
dictionary[[1]]
class(dictionary[[1]] )
g1 <- data_frame()
g1 <- rbind(g1, dictionary[[1]])
g1
# if (!require("devtools")) install.packages("devtools")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
#setwd("E:/study/Columbia University/2018FALL/ads5243/project4/Fall2018-Project4-sec1--sec1-proj4-grp5")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
### only process one of the files in the folder as an example, in your project, you need to use all the files
current_file_name <- sub(".txt","",file_name_vec[5])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
setwd("~/Documents/GitHub/Fall2018-Project4-sec1--sec1-proj4-grp5")
# if (!require("devtools")) install.packages("devtools")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
#setwd("E:/study/Columbia University/2018FALL/ads5243/project4/Fall2018-Project4-sec1--sec1-proj4-grp5")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
### only process one of the files in the folder as an example, in your project, you need to use all the files
current_file_name <- sub(".txt","",file_name_vec[5])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
# if (!require("devtools")) install.packages("devtools")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
setwd("/Users/janechen/Documents/GitHub/Fall2018-Project4-sec1--sec1-proj4-grp5")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
# if (!require("devtools")) install.packages("devtools")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
setwd("/Users/janechen/Documents/GitHub/Fall2018-Project4-sec1--sec1-proj4-grp5/lib")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
### only process one of the files in the folder as an example, in your project, you need to use all the files
current_file_name <- sub(".txt","",file_name_vec[5])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
current_file_name
# Save the ground truth dictionary
group <- c()
dictionary <- list()
for(i in 1:length(file_name_vec)){
current_file_name <- sub(".txt","",file_name_vec[i])
current_group <- substr(current_file_name,1,6)
group <- c(group, current_group)
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
#clean_ground_truth_txt = paste(current_ground_truth_txt, collapse = " ") # zx2229
#ground_truth_vec <- str_split(clean_ground_truth_txt," ")[[1]] # zx2229
current_ground_truth_txt = gsub("..."," ",current_ground_truth_txt,fixed = TRUE)
current_ground_truth_txt = gsub("\"","", current_ground_truth_txt,fixed=TRUE)
corpus <- VCorpus(VectorSource(current_ground_truth_txt))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dictionary[[i]] <- dict
}
# if (!require("devtools")) install.packages("devtools")
# if (!require("pacman")) {
#   ## devtools is required
#  library(devtools)
#  install_github("trinker/pacman")
# }
library(devtools)
library(pacman)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
setwd("/Users/janechen/Documents/GitHub/Fall2018-Project4-sec1--sec1-proj4-grp5/lib")
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
# Save the ground truth dictionary
group <- c()
dictionary <- list()
for(i in 1:length(file_name_vec)){
current_file_name <- sub(".txt","",file_name_vec[i])
current_group <- substr(current_file_name,1,6)
group <- c(group, current_group)
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
#clean_ground_truth_txt = paste(current_ground_truth_txt, collapse = " ") # zx2229
#ground_truth_vec <- str_split(clean_ground_truth_txt," ")[[1]] # zx2229
current_ground_truth_txt = gsub("..."," ",current_ground_truth_txt,fixed = TRUE)
current_ground_truth_txt = gsub("\"","", current_ground_truth_txt,fixed=TRUE)
corpus <- VCorpus(VectorSource(current_ground_truth_txt))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dictionary[[i]] <- dict
}
current_file_name <- sub(".txt","",file_name_vec[i])
file_name_vec
# Save the ground truth dictionary
group <- c()
dictionary <- list()
for(i in 1:length(file_name_vec)){
current_file_name <- sub(".txt","",file_name_vec[i])
current_group <- substr(current_file_name,1,6)
group <- c(group, current_group)
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
#clean_ground_truth_txt = paste(current_ground_truth_txt, collapse = " ") # zx2229
#ground_truth_vec <- str_split(clean_ground_truth_txt," ")[[1]] # zx2229
current_ground_truth_txt = gsub("..."," ",current_ground_truth_txt,fixed = TRUE)
current_ground_truth_txt = gsub("\"","", current_ground_truth_txt,fixed=TRUE)
corpus <- VCorpus(VectorSource(current_ground_truth_txt))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
dictionary[[i]] <- dict
}
for(i in c(1:length(file_name_vec))){
current_file_name <- sub(".txt","",file_name_vec[i])
## png folder is not provided on github (the code is only on demonstration purpose)
current_tesseract_txt <- tesseract::ocr(paste("../data/png/",current_file_name,".png",sep=""))
### clean the tessetact text (separate line by "\n", delete null string, transter to lower case)
clean_tesseract_txt <- strsplit(current_tesseract_txt,"\n")[[1]]
clean_tesseract_txt <- clean_tesseract_txt[clean_tesseract_txt!=""]
### save tesseract text file
writeLines(clean_tesseract_txt, paste("../data/tesseract/",current_file_name,".txt",sep=""))
}
for(i in c(1:length(file_name_vec))){
current_file_name <- sub(".txt","",file_name_vec[i])
## png folder is not provided on github (the code is only on demonstration purpose)
current_tesseract_txt <- tesseract::ocr(paste("../data/png/",current_file_name,".png",sep=""))
### clean the tessetact text (separate line by "\n", delete null string, transter to lower case)
clean_tesseract_txt <- strsplit(current_tesseract_txt,"\n")[[1]]
clean_tesseract_txt <- clean_tesseract_txt[clean_tesseract_txt!=""]
### save tesseract text file
writeLines(clean_tesseract_txt, paste("../data/tesseract/",current_file_name,".txt",sep=""))
}
### only process one of the files in the folder as an example, in your project, you need to use all the files
current_file_name <- sub(".txt","",file_name_vec[5])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
